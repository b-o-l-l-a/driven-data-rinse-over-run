{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import git\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, metrics\n",
    "\n",
    "def get_git_root(path):\n",
    "\n",
    "        git_repo = git.Repo(path, search_parent_directories=True)\n",
    "        #git_root = git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "        \n",
    "        return git_repo.working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greg.bolla/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/numpy/lib/arraysetops.py:571: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "top_level_git_dir = get_git_root(os.getcwd())\n",
    "raw_data_dir = os.path.join(top_level_git_dir, \"data\", \"raw\")\n",
    "\n",
    "train_csv_path = os.path.join(raw_data_dir, \"train_values.csv\")\n",
    "test_csv_path = os.path.join(raw_data_dir, \"test_values.csv\")\n",
    "train_labels_csv_path = os.path.join(raw_data_dir, \"train_labels.csv\")\n",
    "submission_format_csv_path = os.path.join(raw_data_dir, \"submission_format.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path, index_col = \"row_id\")\n",
    "train_labels_df = pd.read_csv(train_labels_csv_path, index_col = \"process_id\")\n",
    "test_df = pd.read_csv(test_csv_path, index_col = \"row_id\")\n",
    "submission_format_csv_path = pd.read_csv(submission_format_csv_path, index_col = \"process_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_full_df(df):\n",
    "\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    \n",
    "    df = df.assign(turbidity_in_liters = \\\n",
    "        np.maximum(0, df.return_flow) * df.return_turbidity)\n",
    "\n",
    "    df['process_phase'] = df.process_id.astype(str) + \"_\" + df.phase.astype(str)\n",
    "    df = df[df.phase != \"final_rinse\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_metadata(df):\n",
    "    meta_df = df[[\"process_id\", \"pipeline\"]].drop_duplicates().set_index(\"process_id\")\n",
    "    meta_df = pd.get_dummies(meta_df)\n",
    "    \n",
    "    if 'L12' not in meta_df.columns:\n",
    "        meta_df['pipeline_L12'] = False\n",
    "    \n",
    "    for col in meta_df.columns:\n",
    "        if \"pipeline\" in col:\n",
    "            meta_df[col] = meta_df[col].astype(bool)\n",
    "            \n",
    "    meta_df[\"num_phases\"] = df.groupby(\"process_id\")[\"phase\"].apply(lambda x: x.nunique())\n",
    "    \n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_cols = [\n",
    "    'process_id',\n",
    "    'timestamp',\n",
    "    'supply_flow',\n",
    "    'supply_pressure',\n",
    "    'return_temperature',\n",
    "    'return_conductivity',\n",
    "    'return_turbidity',\n",
    "    'return_flow',\n",
    "    'tank_level_pre_rinse',\n",
    "    'tank_level_caustic',\n",
    "    'tank_level_acid',\n",
    "    'tank_level_clean_water',\n",
    "    'tank_temperature_pre_rinse',\n",
    "    'tank_temperature_caustic',\n",
    "    'tank_temperature_acid',\n",
    "    'tank_concentration_caustic',\n",
    "    'tank_concentration_acid',\n",
    "    \"turbidity_in_liters\"\n",
    "]\n",
    "\n",
    "def prep_time_series_features(df, columns = None):\n",
    "    \n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    \n",
    "    df = df.sort_values(by=[\"process_id\", \"timestamp\"], ascending=True)\n",
    "    process_duration_ts = df.groupby('process_id')[\"timestamp\"].max() - df.groupby('process_id')[\"timestamp\"].min() \n",
    "    process_duration_ts = process_duration_ts.rename('process_duration')\n",
    "    process_duration = process_duration_ts.apply(lambda row: row.total_seconds())\n",
    "    \n",
    "    ts_df = df[ts_cols].set_index('process_id')\n",
    "    \n",
    "    # define fxn before calling in .agg to make col name more descriptive (in place of <lambda>)\n",
    "    def last_five_mean(x):\n",
    "        return x.tail(5).mean()\n",
    "    \n",
    "    ts_features_agg_df = ts_df.groupby('process_id').agg(['min', 'max', 'mean', 'std', last_five_mean])\n",
    "    \n",
    "    ts_features_df = pd.concat([process_duration, ts_features_agg_df], axis = 1)\n",
    "    return ts_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dummy_vars(df):\n",
    "    \n",
    "    categorical_cols = [\"num_phases\"]\n",
    "\n",
    "    for cat_col in categorical_cols:\n",
    "        dummy_df = pd.get_dummies(df[cat_col], prefix=cat_col, dummy_na = False)\n",
    "        dummy_df = dummy_df.astype('bool')\n",
    "\n",
    "        drop_val = df.groupby([cat_col]).size().idxmax()\n",
    "\n",
    "        drop_col = \"{}_{}\".format(cat_col, drop_val)\n",
    "        df = pd.concat([df, dummy_df], axis=1)\n",
    "        df = df.drop(drop_col, axis=1)    \n",
    "        df[cat_col] = df[cat_col].astype(object)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feature_df(df):\n",
    "    \n",
    "    new_col_names = []\n",
    "    for col in df.columns.ravel():\n",
    "        if isinstance(col, str):\n",
    "            new_col_names.append(col)\n",
    "        elif isinstance(col, tuple):\n",
    "            col_name = \"{}_{}\".format(col[0], col[1])\n",
    "            new_col_names.append(col_name)\n",
    "    df.columns = new_col_names\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(df):\n",
    "    \n",
    "    prepped_df = prep_full_df(df)\n",
    "    metadata_df = prep_metadata(prepped_df)\n",
    "    time_series_df = prep_time_series_features(prepped_df)\n",
    "    \n",
    "    dfs_to_concat = [metadata_df, time_series_df]\n",
    "    \n",
    "    feature_df = pd.concat(dfs_to_concat, axis=1)\n",
    "    feature_df = prep_dummy_vars(feature_df)\n",
    "    \n",
    "    df_to_return = clean_feature_df(feature_df)\n",
    "\n",
    "    return df_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_L1</th>\n",
       "      <th>pipeline_L10</th>\n",
       "      <th>pipeline_L11</th>\n",
       "      <th>pipeline_L12</th>\n",
       "      <th>pipeline_L2</th>\n",
       "      <th>pipeline_L3</th>\n",
       "      <th>pipeline_L4</th>\n",
       "      <th>pipeline_L6</th>\n",
       "      <th>pipeline_L7</th>\n",
       "      <th>pipeline_L8</th>\n",
       "      <th>...</th>\n",
       "      <th>tank_concentration_acid_last_five_mean</th>\n",
       "      <th>turbidity_in_liters_min</th>\n",
       "      <th>turbidity_in_liters_max</th>\n",
       "      <th>turbidity_in_liters_mean</th>\n",
       "      <th>turbidity_in_liters_std</th>\n",
       "      <th>turbidity_in_liters_last_five_mean</th>\n",
       "      <th>num_phases_1</th>\n",
       "      <th>num_phases_2</th>\n",
       "      <th>num_phases_3</th>\n",
       "      <th>final_rinse_total_turbidity_liter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>44.653038</td>\n",
       "      <td>818.406942</td>\n",
       "      <td>1.579919e+06</td>\n",
       "      <td>105488.460366</td>\n",
       "      <td>174650.861160</td>\n",
       "      <td>30300.051942</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.318275e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>44.229616</td>\n",
       "      <td>499.442792</td>\n",
       "      <td>2.976941e+06</td>\n",
       "      <td>854203.372900</td>\n",
       "      <td>563689.439444</td>\n",
       "      <td>949644.159635</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4.375286e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>44.716846</td>\n",
       "      <td>152.522484</td>\n",
       "      <td>1.431140e+06</td>\n",
       "      <td>44218.000816</td>\n",
       "      <td>127420.220308</td>\n",
       "      <td>5287.641592</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.271977e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>45.226021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.162818e+06</td>\n",
       "      <td>212923.854423</td>\n",
       "      <td>387856.686586</td>\n",
       "      <td>22306.533910</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7.197830e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>43.952939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.066256e+05</td>\n",
       "      <td>23587.698324</td>\n",
       "      <td>26813.228206</td>\n",
       "      <td>45723.010454</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.133107e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pipeline_L1  pipeline_L10  pipeline_L11  pipeline_L12  \\\n",
       "process_id                                                          \n",
       "20001             False         False         False         False   \n",
       "20002             False         False         False         False   \n",
       "20003             False         False         False         False   \n",
       "20004             False         False         False         False   \n",
       "20005             False         False         False         False   \n",
       "\n",
       "            pipeline_L2  pipeline_L3  pipeline_L4  pipeline_L6  pipeline_L7  \\\n",
       "process_id                                                                    \n",
       "20001             False        False         True        False        False   \n",
       "20002             False         True        False        False        False   \n",
       "20003             False         True        False        False        False   \n",
       "20004             False        False        False        False         True   \n",
       "20005             False        False        False        False         True   \n",
       "\n",
       "            pipeline_L8                ...                  \\\n",
       "process_id                             ...                   \n",
       "20001             False                ...                   \n",
       "20002             False                ...                   \n",
       "20003             False                ...                   \n",
       "20004             False                ...                   \n",
       "20005             False                ...                   \n",
       "\n",
       "            tank_concentration_acid_last_five_mean turbidity_in_liters_min  \\\n",
       "process_id                                                                   \n",
       "20001                                    44.653038              818.406942   \n",
       "20002                                    44.229616              499.442792   \n",
       "20003                                    44.716846              152.522484   \n",
       "20004                                    45.226021                0.000000   \n",
       "20005                                    43.952939                0.000000   \n",
       "\n",
       "            turbidity_in_liters_max  turbidity_in_liters_mean  \\\n",
       "process_id                                                      \n",
       "20001                  1.579919e+06             105488.460366   \n",
       "20002                  2.976941e+06             854203.372900   \n",
       "20003                  1.431140e+06              44218.000816   \n",
       "20004                  3.162818e+06             212923.854423   \n",
       "20005                  2.066256e+05              23587.698324   \n",
       "\n",
       "            turbidity_in_liters_std  turbidity_in_liters_last_five_mean  \\\n",
       "process_id                                                                \n",
       "20001                 174650.861160                        30300.051942   \n",
       "20002                 563689.439444                       949644.159635   \n",
       "20003                 127420.220308                         5287.641592   \n",
       "20004                 387856.686586                        22306.533910   \n",
       "20005                  26813.228206                        45723.010454   \n",
       "\n",
       "            num_phases_1  num_phases_2  num_phases_3  \\\n",
       "process_id                                             \n",
       "20001              False         False         False   \n",
       "20002              False          True         False   \n",
       "20003              False         False         False   \n",
       "20004              False         False         False   \n",
       "20005               True         False         False   \n",
       "\n",
       "            final_rinse_total_turbidity_liter  \n",
       "process_id                                     \n",
       "20001                            4.318275e+06  \n",
       "20002                            4.375286e+05  \n",
       "20003                            4.271977e+05  \n",
       "20004                            7.197830e+05  \n",
       "20005                            4.133107e+05  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_df = create_feature_matrix(train_df)\n",
    "\n",
    "indices_to_keep = list(set(train_features_df.index).intersection(set(train_labels_df.index)))\n",
    "# figure out why 16 indices dropped out of train_features_df\n",
    "train_labels_df = train_labels_df[train_labels_df.index.isin(indices_to_keep)]\n",
    "train_features_w_response = train_features_df.join(train_labels_df)\n",
    "train_features_w_response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_var = [\"final_rinse_total_turbidity_liter\"]\n",
    "pred_df = train_features_w_response.drop(response_var, axis=1)\n",
    "response_df = train_features_w_response[response_var]\n",
    "\n",
    "pred_train, pred_test, response_train, response_test = train_test_split(pred_df, response_df, test_size=0.25, random_state=223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_r2_score(lm, y, y_pred):\n",
    "    adj_r2 = 1 - float(len(y)-1)/(len(y)-len(lm.coef_)-1)*(1 - metrics.r2_score(y,y_pred))\n",
    "    return adj_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_regression_df = pd.DataFrame()\n",
    "\n",
    "for col_name in pred_train.columns:\n",
    "    categorical = True if pred_train[col_name].dtype == \"object\" else False\n",
    "\n",
    "    full_df_col_list = pred_df.columns.values\n",
    "    if categorical == True:\n",
    "        col_vars = [var for var in full_df_col_list if \"{}_\".format(col_name) in var]\n",
    "    else: \n",
    "        col_vars = [col_name]\n",
    "        \n",
    "    x_train_df = pred_train[col_vars]\n",
    "    x_test_df = pred_test[col_vars]\n",
    "    \n",
    "    x_model = linear_model.LinearRegression()\n",
    "    x_results = x_model.fit(x_train_df, response_train[response_var])\n",
    "    \n",
    "    y_predicted_test = x_model.predict(x_test_df)\n",
    "    med_absolute_error = metrics.median_absolute_error(response_test[response_var], y_predicted_test)\n",
    "    r2 = metrics.r2_score(response_test[response_var],y_predicted_test)\n",
    "    adj_r2 = adj_r2_score(x_results, response_test[response_var],y_predicted_test)\n",
    "    \n",
    "    coef_dict = {}\n",
    "    model_rows = []\n",
    "\n",
    "    for idx, col in enumerate(x_train_df.columns.values):\n",
    "        if categorical == True:\n",
    "            pred_coef = x_results.coef_[0][idx]\n",
    "        else:\n",
    "            pred_coef = x_results.coef_[idx]\n",
    "        model_row = {}\n",
    "        model_row['model'] = col_name\n",
    "        model_row['model_r2'] = r2\n",
    "        model_row['model_adj_r2'] = adj_r2\n",
    "        model_row['median_absolute_error'] = med_absolute_error\n",
    "        model_row['pred_col'] = col if categorical == True else None\n",
    "        model_row['pred_coef'] = pred_coef\n",
    "        model_row['categorical'] = categorical\n",
    "        model_rows.append(model_row)\n",
    "        \n",
    "    single_regression_df = single_regression_df.append(model_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1093748.2747877538"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_results.coef_[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "num_phases_1\n",
      "1\n",
      "num_phases_2\n",
      "2\n",
      "num_phases_3\n"
     ]
    }
   ],
   "source": [
    "for idx, col in enumerate(x_train_df.columns.values):\n",
    "    print(idx)\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337956.64445802866"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_results.coef_[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_regression_df.to_csv(\"single_reg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
