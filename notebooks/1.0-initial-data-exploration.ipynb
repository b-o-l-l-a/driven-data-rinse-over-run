{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import git\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import time\n",
    "\n",
    "def get_git_root(path):\n",
    "\n",
    "        git_repo = git.Repo(path, search_parent_directories=True)\n",
    "        #git_root = git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "        \n",
    "        return git_repo.working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_level_git_dir = get_git_root(os.getcwd())\n",
    "raw_data_dir = os.path.join(top_level_git_dir, \"data\", \"raw\")\n",
    "\n",
    "train_csv_path = os.path.join(raw_data_dir, \"train_values.csv\")\n",
    "test_csv_path = os.path.join(raw_data_dir, \"test_values.csv\")\n",
    "train_labels_csv_path = os.path.join(raw_data_dir, \"train_labels.csv\")\n",
    "submission_format_csv_path = os.path.join(raw_data_dir, \"submission_format.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path, index_col = \"row_id\")\n",
    "train_labels_df = pd.read_csv(train_labels_csv_path, index_col = \"process_id\")\n",
    "test_df = pd.read_csv(test_csv_path, index_col = \"row_id\")\n",
    "submission_format_csv_path = pd.read_csv(submission_format_csv_path, index_col = \"process_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = {}\n",
    "for proc_id in train_df.process_id.unique():\n",
    "    final_phase_for_proc = train_df[(train_df.process_id == proc_id) & (train_df.target_time_period == True)]\n",
    "    final_phase_for_proc = final_phase_for_proc.assign(final_phase_turbidity = \\\n",
    "        np.maximum(0, final_phase_for_proc.return_flow) * final_phase_for_proc.return_turbidity)\n",
    "    proc_id_response = final_phase_for_proc[\"final_phase_turbidity\"].sum()\n",
    "    \n",
    "    response_dict[proc_id] = proc_id_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_full_df(df):\n",
    "\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    \n",
    "    df = df.assign(turbidity_in_liters = \\\n",
    "        np.maximum(0, df.return_flow) * df.return_turbidity)\n",
    "\n",
    "    df['process_phase'] = df.process_id.astype(str) + \"_\" + df.phase.astype(str)\n",
    "    df = df[df.phase != \"final_rinse\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_metadata(df):\n",
    "    meta_df = df[[\"process_id\", \"pipeline\"]].drop_duplicates().set_index(\"process_id\")\n",
    "    meta_df = pd.get_dummies(meta_df)\n",
    "    \n",
    "    if 'L12' not in meta_df.columns:\n",
    "        meta_df['pipeline_L12'] = False\n",
    "    \n",
    "    for col in meta_df.columns:\n",
    "        if \"pipeline\" in col:\n",
    "            meta_df[col] = meta_df[col].astype(bool)\n",
    "    meta_df[\"num_phases\"] = df.groupby(\"process_id\")[\"phase\"].apply(lambda x: x.nunique())\n",
    "    return meta_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_cols = [\n",
    "    'process_id',\n",
    "    'timestamp',\n",
    "    'supply_flow',\n",
    "    'supply_pressure',\n",
    "    'return_temperature',\n",
    "    'return_conductivity',\n",
    "    'return_turbidity',\n",
    "    'return_flow',\n",
    "    'tank_level_pre_rinse',\n",
    "    'tank_level_caustic',\n",
    "    'tank_level_acid',\n",
    "    'tank_level_clean_water',\n",
    "    'tank_temperature_pre_rinse',\n",
    "    'tank_temperature_caustic',\n",
    "    'tank_temperature_acid',\n",
    "    'tank_concentration_caustic',\n",
    "    'tank_concentration_acid',\n",
    "    \"turbidity_in_liters\"\n",
    "]\n",
    "\n",
    "def prep_time_series_features(df, columns = None):\n",
    "    \n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    \n",
    "    df = df.sort_values(by=[\"process_id\", \"timestamp\"], ascending=True)\n",
    "    process_duration = df.groupby('process_id')[\"timestamp\"].max() - df.groupby('process_id')[\"timestamp\"].min() \n",
    "    process_duration = process_duration.rename('process_duration')\n",
    "    \n",
    "    ts_df = df[ts_cols].set_index('process_id')\n",
    "    \n",
    "    # define fxn before calling in .agg to make col name more descriptive (in place of <lambda>)\n",
    "    def last_five_mean(x):\n",
    "        return x.tail(5).mean()\n",
    "    \n",
    "    ts_features_agg_df = ts_df.groupby('process_id').agg(['min', 'max', 'mean', 'std', last_five_mean])\n",
    "    \n",
    "    ts_features_df = pd.concat([process_duration, ts_features_agg_df], axis = 1)\n",
    "    return ts_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feature_df(df):\n",
    "    \n",
    "    new_col_names = []\n",
    "    for col in df.columns.ravel():\n",
    "        if isinstance(col, str):\n",
    "            new_col_names.append(col)\n",
    "        elif isinstance(col, tuple):\n",
    "            col_name = \"{}_{}\".format(col[0], col[1])\n",
    "            new_col_names.append(col_name)\n",
    "    df.columns = new_col_names\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(df):\n",
    "    \n",
    "    prepped_df = prep_full_df(df)\n",
    "    metadata_df = prep_metadata(prepped_df)\n",
    "    time_series_df = prep_time_series_features(prepped_df)\n",
    "    \n",
    "    dfs_to_concat = [metadata_df, time_series_df]\n",
    "    \n",
    "    feature_df = pd.concat(dfs_to_concat, axis=1)\n",
    "    \n",
    "    df_to_return = clean_feature_df(feature_df)\n",
    "\n",
    "    \n",
    "    return df_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_df = create_feature_matrix(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_keep = list(set(train_features_df.index).intersection(set(train_labels_df.index)))\n",
    "\n",
    "# figure out why 16 indices dropped out of train_features_df\n",
    "train_labels_df = train_labels_df[train_labels_df.index.isin(indices_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_w_response = train_features_df.join(train_labels_df)\n",
    "train_features_w_response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = sns.violinplot(x = 'pipeline_L3', y = 'final_rinse_total_turbidity_liter', data = train_features_w_response).get_figure()\n",
    "plt.savefig(\"output.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"num_phases\", y=\"final_rinse_total_turbidity_liter\", data=train_features_w_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.crosstab(index=train_features_w_response[\"num_phases\"], columns=\"count\")\n",
    "#a.loc[True][\"count\"]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_features_w_response\n",
    " .plot\n",
    " .scatter(x='supply_pressure_max', y='final_rinse_total_turbidity_liter')\n",
    " .set(title='Title',\n",
    "      xlabel='supply_pressure_max',\n",
    "      ylabel='final_rinse_total_turbidity_liter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = sns.lmplot(\"supply_pressure_max\", \"final_rinse_total_turbidity_liter\", fit_reg = False, size=8, data=train_features_w_response)\n",
    "ax = plt.axes.flatten()\n",
    "title = ax[0].set_title(\"Title\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns_plot = sns.distplot(train_features_w_response[\"turbidity_in_liters_mean\"]).get_figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_features_w_response.columns\n",
    "for col in train_features_w_response.columns:\n",
    "    print(col, train_features_w_response[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_features_w_response.columns:\n",
    "    if \"pipeline\" in col:\n",
    "        train_features_w_response[col] = train_features_w_response[col].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_plot(df, col_name, col_type, response_var):\n",
    "    \n",
    "    plot_output_folder = os.path.join(top_level_git_dir, \"src\", \"visualizations\")\n",
    "    col_plot_output_folder = os.path.join(plot_output_folder, col_name)\n",
    "    \n",
    "    if not os.path.exists(col_plot_output_folder):\n",
    "        os.makedirs(col_plot_output_folder)\n",
    "        \n",
    "    xtab = pd.crosstab(index=df[col_name], columns=\"count\")\n",
    "    if col_type == \"bool\":\n",
    "        true_ct = xtab.loc[True][\"count\"] if True in list(xtab.index.values) else None\n",
    "        false_ct = xtab.loc[False][\"count\"]\n",
    "        plot_title = \"False: {} / True: {}\".format(col_name, false_ct, )\n",
    "    else:\n",
    "        plot_title = col_name\n",
    "    violin_plt = sns.violinplot(x = col_name, y = response_var, data = df).set_title(plot_title).get_figure()\n",
    "    violin_plt.savefig(os.path.join(col_plot_output_folder, \"violin_plot.png\"))\n",
    "    plt.pyplot.close()\n",
    "    #sns_plot = sns.distplot(train_features_w_response.final_rinse_total_turbidity_liter).get_figure()\n",
    "    #sns_plot.savefig(\"output.png\")\n",
    "    return\n",
    "\n",
    "def get_continuous_plot(df, col_name, response_var):\n",
    "\n",
    "    plot_output_folder = os.path.join(top_level_git_dir, \"src\", \"visualizations\")\n",
    "    col_plot_output_folder = os.path.join(plot_output_folder, col_name)\n",
    "    \n",
    "    if not os.path.exists(col_plot_output_folder):\n",
    "        os.makedirs(col_plot_output_folder)\n",
    "    \n",
    "    scatter_plt = sns.lmplot(x=col_name, y=response_var, fit_reg = False, size=8, data=df)\n",
    "    scatter_plt_ax = scatter_plt.axes.flatten()\n",
    "    title = scatter_plt_ax[0].set_title(col_name)\n",
    "    scatter_plt.savefig(os.path.join(col_plot_output_folder, \"scatter_plot.png\"))\n",
    "    plt.pyplot.close()\n",
    "\n",
    "    dist_plt = sns.distplot(df[col_name]).get_figure()\n",
    "    dist_plt.savefig(os.path.join(col_plot_output_folder, \"density_plot.png\"))\n",
    "    plt.pyplot.close()\n",
    "\n",
    "    return\n",
    "\n",
    "def create_eda_plots(df, response_var = 'final_rinse_total_turbidity_liter'):\n",
    "    \n",
    "    col_list = df.columns\n",
    "    col_type_dict = {}\n",
    "    \n",
    "    for col in col_list:\n",
    "        if col == \"num_phases\":\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        col_type_dict[col] = col_type\n",
    "        \n",
    "    for col, col_type in col_type_dict.items():\n",
    "        print(\"-- {}\".format(col))    \n",
    "        if col_type in [\"bool\", \"int64\"]:\n",
    "            \n",
    "            get_categorical_plot(df, col, col_type, response_var)\n",
    "        \n",
    "        elif col_type in [\"float64\"]:\n",
    "            \n",
    "            get_continuous_plot(df, col, response_var)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_eda_plots(train_features_w_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = \"supply_flow_min\"\n",
    "a = sns.distplot(train_features_w_response[col_name])\n",
    "pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "fig = pyplot.hist(train_features_w_response[col_name], color = 'blue', edgecolor = 'black', bins=10, label=col_name)\n",
    "pyplot.title(col_name)\n",
    "pyplot.savefig(\"pyplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_w_response[col_name].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_w_response[col_name].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
