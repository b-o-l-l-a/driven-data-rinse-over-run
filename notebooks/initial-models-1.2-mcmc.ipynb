{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import git\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, metrics\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "\n",
    "def get_git_root(path):\n",
    "\n",
    "        git_repo = git.Repo(path, search_parent_directories=True)\n",
    "        #git_root = git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "        \n",
    "        return git_repo.working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greg.bolla/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "top_level_git_dir = get_git_root(os.getcwd())\n",
    "raw_data_dir = os.path.join(top_level_git_dir, \"data\", \"raw\")\n",
    "\n",
    "train_csv_path = os.path.join(raw_data_dir, \"train_values.csv\")\n",
    "test_csv_path = os.path.join(raw_data_dir, \"test_values.csv\")\n",
    "train_labels_csv_path = os.path.join(raw_data_dir, \"train_labels.csv\")\n",
    "submission_format_csv_path = os.path.join(raw_data_dir, \"submission_format.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path, index_col = \"row_id\")\n",
    "train_labels_df = pd.read_csv(train_labels_csv_path, index_col = \"process_id\")\n",
    "test_df = pd.read_csv(test_csv_path, index_col = \"row_id\")\n",
    "submission_format_df = pd.read_csv(submission_format_csv_path, index_col = \"process_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_full_df(df):\n",
    "\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    \n",
    "    df = df.assign(turbidity_in_liters = \\\n",
    "        np.maximum(0, df.return_flow) * df.return_turbidity)\n",
    "\n",
    "    df['process_phase'] = df.process_id.astype(str) + \"_\" + df.phase.astype(str)\n",
    "    df = df[df.phase != \"final_rinse\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_metadata(df):\n",
    "    meta_df = df[[\"process_id\", \"pipeline\"]].drop_duplicates().set_index(\"process_id\")\n",
    "    meta_df = pd.get_dummies(meta_df)\n",
    "    \n",
    "    if 'L12' not in meta_df.columns:\n",
    "        meta_df['pipeline_L12'] = False\n",
    "    \n",
    "    for col in meta_df.columns:\n",
    "        if \"pipeline\" in col:\n",
    "            meta_df[col] = meta_df[col].astype(bool)\n",
    "            \n",
    "    meta_df[\"num_phases\"] = df.groupby(\"process_id\")[\"phase\"].apply(lambda x: x.nunique())\n",
    "    \n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_cols = [\n",
    "    'process_id',\n",
    "    'timestamp',\n",
    "    'supply_flow',\n",
    "    'supply_pressure',\n",
    "    'return_temperature',\n",
    "    'return_conductivity',\n",
    "    'return_turbidity',\n",
    "    'return_flow',\n",
    "    'tank_level_pre_rinse',\n",
    "    'tank_level_caustic',\n",
    "    'tank_level_acid',\n",
    "    'tank_level_clean_water',\n",
    "    'tank_temperature_pre_rinse',\n",
    "    'tank_temperature_caustic',\n",
    "    'tank_temperature_acid',\n",
    "    'tank_concentration_caustic',\n",
    "    'tank_concentration_acid',\n",
    "    \"turbidity_in_liters\"\n",
    "]\n",
    "\n",
    "def prep_time_series_features(df, columns = None):\n",
    "    \n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    \n",
    "    df = df.sort_values(by=[\"process_id\", \"timestamp\"], ascending=True)\n",
    "    process_duration_ts = df.groupby('process_id')[\"timestamp\"].max() - df.groupby('process_id')[\"timestamp\"].min() \n",
    "    process_duration_ts = process_duration_ts.rename('process_duration')\n",
    "    process_duration = process_duration_ts.apply(lambda row: row.total_seconds())\n",
    "    \n",
    "    ts_df = df[ts_cols].set_index('process_id')\n",
    "    \n",
    "    # define fxn before calling in .agg to make col name more descriptive (in place of <lambda>)\n",
    "    def last_five_mean(x):\n",
    "        return x.tail(5).mean()\n",
    "    \n",
    "    ts_features_agg_df = ts_df.groupby('process_id').agg(['min', 'max', 'mean', 'std', last_five_mean])\n",
    "    \n",
    "    ts_features_df = pd.concat([process_duration, ts_features_agg_df], axis = 1)\n",
    "    return ts_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dummy_vars(df):\n",
    "    \n",
    "    categorical_cols = [\"num_phases\"]\n",
    "\n",
    "    for cat_col in categorical_cols:\n",
    "        dummy_df = pd.get_dummies(df[cat_col], prefix=cat_col, dummy_na = False)\n",
    "        dummy_df = dummy_df.astype('bool')\n",
    "\n",
    "        drop_val = df.groupby([cat_col]).size().idxmax()\n",
    "\n",
    "        drop_col = \"{}_{}\".format(cat_col, drop_val)\n",
    "        df = pd.concat([df, dummy_df], axis=1)\n",
    "        df = df.drop(drop_col, axis=1)    \n",
    "        df[cat_col] = df[cat_col].astype(object)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feature_df(df):\n",
    "    \n",
    "    new_col_names = []\n",
    "    for col in df.columns.ravel():\n",
    "        if isinstance(col, str):\n",
    "            new_col_names.append(col)\n",
    "        elif isinstance(col, tuple):\n",
    "            col_name = \"{}_{}\".format(col[0], col[1])\n",
    "            new_col_names.append(col_name)\n",
    "    df.columns = new_col_names\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(df):\n",
    "    \n",
    "    prepped_df = prep_full_df(df)\n",
    "    metadata_df = prep_metadata(prepped_df)\n",
    "    time_series_df = prep_time_series_features(prepped_df)\n",
    "    \n",
    "    dfs_to_concat = [metadata_df, time_series_df]\n",
    "    \n",
    "    feature_df = pd.concat(dfs_to_concat, axis=1)\n",
    "    feature_df = prep_dummy_vars(feature_df)\n",
    "    \n",
    "    df_to_return = clean_feature_df(feature_df)\n",
    "\n",
    "    return df_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_L1</th>\n",
       "      <th>pipeline_L10</th>\n",
       "      <th>pipeline_L11</th>\n",
       "      <th>pipeline_L12</th>\n",
       "      <th>pipeline_L2</th>\n",
       "      <th>pipeline_L3</th>\n",
       "      <th>pipeline_L4</th>\n",
       "      <th>pipeline_L6</th>\n",
       "      <th>pipeline_L7</th>\n",
       "      <th>pipeline_L8</th>\n",
       "      <th>...</th>\n",
       "      <th>tank_concentration_acid_last_five_mean</th>\n",
       "      <th>turbidity_in_liters_min</th>\n",
       "      <th>turbidity_in_liters_max</th>\n",
       "      <th>turbidity_in_liters_mean</th>\n",
       "      <th>turbidity_in_liters_std</th>\n",
       "      <th>turbidity_in_liters_last_five_mean</th>\n",
       "      <th>num_phases_1</th>\n",
       "      <th>num_phases_2</th>\n",
       "      <th>num_phases_3</th>\n",
       "      <th>final_rinse_total_turbidity_liter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>44.653038</td>\n",
       "      <td>818.406942</td>\n",
       "      <td>1.579919e+06</td>\n",
       "      <td>105488.460366</td>\n",
       "      <td>174650.861160</td>\n",
       "      <td>30300.051942</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.318275e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>44.229616</td>\n",
       "      <td>499.442792</td>\n",
       "      <td>2.976941e+06</td>\n",
       "      <td>854203.372900</td>\n",
       "      <td>563689.439444</td>\n",
       "      <td>949644.159635</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4.375286e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>44.716846</td>\n",
       "      <td>152.522484</td>\n",
       "      <td>1.431140e+06</td>\n",
       "      <td>44218.000816</td>\n",
       "      <td>127420.220308</td>\n",
       "      <td>5287.641592</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.271977e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>45.226021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.162818e+06</td>\n",
       "      <td>212923.854423</td>\n",
       "      <td>387856.686586</td>\n",
       "      <td>22306.533910</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7.197830e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>43.952939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.066256e+05</td>\n",
       "      <td>23587.698324</td>\n",
       "      <td>26813.228206</td>\n",
       "      <td>45723.010454</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.133107e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pipeline_L1  pipeline_L10  pipeline_L11  pipeline_L12  \\\n",
       "process_id                                                          \n",
       "20001             False         False         False         False   \n",
       "20002             False         False         False         False   \n",
       "20003             False         False         False         False   \n",
       "20004             False         False         False         False   \n",
       "20005             False         False         False         False   \n",
       "\n",
       "            pipeline_L2  pipeline_L3  pipeline_L4  pipeline_L6  pipeline_L7  \\\n",
       "process_id                                                                    \n",
       "20001             False        False         True        False        False   \n",
       "20002             False         True        False        False        False   \n",
       "20003             False         True        False        False        False   \n",
       "20004             False        False        False        False         True   \n",
       "20005             False        False        False        False         True   \n",
       "\n",
       "            pipeline_L8  ...  tank_concentration_acid_last_five_mean  \\\n",
       "process_id               ...                                           \n",
       "20001             False  ...                               44.653038   \n",
       "20002             False  ...                               44.229616   \n",
       "20003             False  ...                               44.716846   \n",
       "20004             False  ...                               45.226021   \n",
       "20005             False  ...                               43.952939   \n",
       "\n",
       "           turbidity_in_liters_min  turbidity_in_liters_max  \\\n",
       "process_id                                                    \n",
       "20001                   818.406942             1.579919e+06   \n",
       "20002                   499.442792             2.976941e+06   \n",
       "20003                   152.522484             1.431140e+06   \n",
       "20004                     0.000000             3.162818e+06   \n",
       "20005                     0.000000             2.066256e+05   \n",
       "\n",
       "            turbidity_in_liters_mean  turbidity_in_liters_std  \\\n",
       "process_id                                                      \n",
       "20001                  105488.460366            174650.861160   \n",
       "20002                  854203.372900            563689.439444   \n",
       "20003                   44218.000816            127420.220308   \n",
       "20004                  212923.854423            387856.686586   \n",
       "20005                   23587.698324             26813.228206   \n",
       "\n",
       "            turbidity_in_liters_last_five_mean  num_phases_1  num_phases_2  \\\n",
       "process_id                                                                   \n",
       "20001                             30300.051942         False         False   \n",
       "20002                            949644.159635         False          True   \n",
       "20003                              5287.641592         False         False   \n",
       "20004                             22306.533910         False         False   \n",
       "20005                             45723.010454          True         False   \n",
       "\n",
       "            num_phases_3  final_rinse_total_turbidity_liter  \n",
       "process_id                                                   \n",
       "20001              False                       4.318275e+06  \n",
       "20002              False                       4.375286e+05  \n",
       "20003              False                       4.271977e+05  \n",
       "20004              False                       7.197830e+05  \n",
       "20005              False                       4.133107e+05  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_df = create_feature_matrix(train_df)\n",
    "\n",
    "indices_to_keep = list(set(train_features_df.index).intersection(set(train_labels_df.index)))\n",
    "# figure out why 16 indices dropped out of train_features_df\n",
    "train_labels_df = train_labels_df[train_labels_df.index.isin(indices_to_keep)]\n",
    "train_features_w_response = train_features_df.join(train_labels_df)\n",
    "train_features_w_response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_var = [\"final_rinse_total_turbidity_liter\"]\n",
    "pred_df = train_features_w_response.drop(response_var, axis=1)\n",
    "response_df = train_features_w_response[response_var]\n",
    "\n",
    "pred_train, pred_test, response_train, response_test = train_test_split(pred_df, response_df, test_size=0.01, random_state=223)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_r2_score(lm, y, y_pred):\n",
    "    adj_r2 = 1 - float(len(y)-1)/(len(y)-len(lm.coef_)-1)*(1 - metrics.r2_score(y,y_pred))\n",
    "    return adj_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mape(pred_array, actual_array):\n",
    "    \n",
    "    threshold = 290000\n",
    "\n",
    "    \n",
    "    mape_array = []\n",
    "    for pred, actual in zip(pred_array, actual_array.values):\n",
    "        #print(\"{} - {}\".format(pred[0], type(pred[0])))\n",
    "        #print(\"{} - {}\".format(actual[0], type(actual[0])))\n",
    "        mape = (abs(pred - actual) / max(abs(actual), threshold))\n",
    "        mape_array.append(mape)\n",
    "        \n",
    "    return mape_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process_id\n",
       "24413      3648.224135\n",
       "27841     91667.214931\n",
       "22114    124728.348050\n",
       "22149      3966.718011\n",
       "25281    191481.966164\n",
       "Name: turbidity_in_liters_mean, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train[\"turbidity_in_liters_mean\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148691.19693241388"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "#pyplot.hist(response_df, bins=5, label=response_var)\n",
    "x1_var = pred_train[\"turbidity_in_liters_mean\"]\n",
    "\n",
    "np.std(pred_train[\"turbidity_in_liters_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.38706859e-01,  4.10296149e-01,  3.83981292e+00,  1.48115418e+00,\n",
       "        4.02779506e-01,  2.46184530e+00, -1.42342679e+00, -1.27520755e+00,\n",
       "        2.38380704e+00, -3.90761758e-01,  6.86815665e-01,  2.10641559e+00,\n",
       "        1.84890360e+00, -8.04359754e-01,  3.93284941e-01,  2.31721220e+00,\n",
       "        3.41651416e+00,  3.39016804e+00,  2.22246532e+00,  3.77308673e-01,\n",
       "        3.43806883e-01,  1.66274112e+00, -1.20663529e-01,  2.18829692e+00,\n",
       "        1.50706675e+00, -1.19159361e+00,  1.44784359e+00, -1.55349860e+00,\n",
       "       -1.40248284e-01, -1.96609652e-02, -1.35472064e+00, -1.59474188e+00,\n",
       "       -1.39656749e+00,  5.29754386e-01,  2.63051387e+00,  5.53932221e-01,\n",
       "        1.76084808e+00,  2.39686504e+00,  1.47396672e+00,  9.07514885e-01,\n",
       "        7.37921664e-02, -3.82899347e-01,  1.49271947e+00,  7.65880501e-01,\n",
       "        2.05273917e+00,  5.63172455e-01,  4.25098874e+00,  3.26909416e-02,\n",
       "        3.93785393e-01,  3.67324277e+00,  1.69575050e+00,  9.38133214e-01,\n",
       "        1.35531685e+00, -2.42854948e+00,  1.26254192e+00,  2.07270390e+00,\n",
       "        2.75833869e+00,  2.60484762e+00,  3.21391580e+00,  4.95643013e+00,\n",
       "        2.31319324e-01,  1.53863552e+00,  1.25983672e+00, -5.57565140e-01,\n",
       "        3.74025866e+00,  1.00427073e+00,  2.44326467e+00,  5.03997740e-01,\n",
       "        1.06029822e+00,  1.48250538e+00, -2.69441500e-01, -1.19520306e+00,\n",
       "        3.20016631e+00, -6.69460228e-01, -2.24215995e+00,  2.10607318e+00,\n",
       "        2.01495136e+00, -8.51855254e-01, -8.99821832e-01, -1.20278122e+00,\n",
       "        1.05077792e+00, -1.43401688e-01,  1.84052098e+00,  1.16665281e+00,\n",
       "        5.60119574e-02, -2.04696786e+00, -1.66062003e+00,  5.51783963e-01,\n",
       "        1.58062230e+00,  1.63826706e+00,  1.16403511e+00,  3.85980814e-01,\n",
       "        2.23665854e+00,  1.23718947e+00, -1.16021703e+00,  1.11137427e+00,\n",
       "        1.65658589e+00, -3.20236525e-03,  1.36931418e+00,  1.33161104e+00])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# True parameter values\n",
    "alpha, sigma = 1, 1\n",
    "beta = [1, 2.5]\n",
    "\n",
    "# Size of dataset\n",
    "size = 100\n",
    "\n",
    "# Predictor variable\n",
    "X1 = np.random.randn(size)\n",
    "X2 = np.random.randn(size) * 0.2\n",
    "\n",
    "# Simulate outcome variable\n",
    "Y = alpha + beta[0]*X1 + beta[1]*X2 + np.random.randn(size)*sigma\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 10 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [sd, x, Intercept]\n",
      "Sampling 2 chains:   0%|          | 0/1020 [00:00<?, ?draws/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, use_mmap, **kwargs)\u001b[0m\n\u001b[1;32m    989\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m                         \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36mrecv_draw\u001b[0;34m(processes, timeout)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mpipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_msg_pipe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-56ed51811e33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_formula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y ~ x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m#y_obs = pm.HalfNormal('y_obs', sd=error, observed=response_train[\"final_rinse_total_turbidity_liter\"].values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, nuts_kwargs, step_kwargs, progressbar, model, random_seed, live_plot, discard_tuned_samples, live_plot_kwargs, compute_convergence_checks, use_mmap, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0m_print_step_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, use_mmap, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mMultiTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_choose_chains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mMultiTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_choose_chains\u001b[0;34m(traces, tune)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not enough samples to build a trace.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "# find prior of response variable by simply looking at the mean/sd of response of train\n",
    "response_var = \"final_rinse_total_turbidity_liter\"\n",
    "x1_var = pred_train[\"turbidity_in_liters_mean\"]\n",
    "std = np.std(response_train[response_var])\n",
    "\n",
    "data = dict(x=pred_train[\"turbidity_in_liters_mean\"], y=response_train[\"final_rinse_total_turbidity_liter\"])\n",
    "# will use half normal as the distribution. pareto may also be appropriate\n",
    "with pm.Model() as turbidity_model: \n",
    "    \n",
    "#     x = pm.HalfNormal('x', sd=150000, observed=pred_train[\"turbidity_in_liters_mean\"])\n",
    "#     intercept = pm.HalfNormal('intercept', sd = 5000000, shape=len(response_train))\n",
    "#     coef = pm.Normal('coef', mu = 0, sd=1, shape=len(response_train))\n",
    "#     error = pm.Normal('error', mu=-500000, sd=7000000)\n",
    "    \n",
    "    #mu = intercept + (coef * x1_var)\n",
    "    \n",
    "    pm.glm.GLM.from_formula('y ~ x', data)\n",
    "    trace = pm.sample(10)\n",
    "    #y_obs = pm.HalfNormal('y_obs', sd=error, observed=response_train[\"final_rinse_total_turbidity_liter\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#response_train[\"final_rinse_total_turbidity_liter\"].values\n",
    "#turbidity_model.check_test_point()\n",
    "turbidity_model.observed_RVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept_log__ -3814.0478981586543\n",
      "coef -4552.4214934961055\n",
      "error -16.68035924022426\n",
      "x -63721.532288925555\n",
      "y_obs -inf\n"
     ]
    }
   ],
   "source": [
    "for RV in turbidity_model.basic_RVs:\n",
    "    print(RV.name, RV.logp(turbidity_model.test_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 10 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [error, coef, intercept]\n",
      "Sampling 2 chains:   0%|          | 0/1020 [00:00<?, ?draws/s]/Users/greg.bolla/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/greg.bolla/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "\n",
      "Bad initial energy, check any log probabilities that are inf or -inf, nan or very small:\n",
      "y_obs   -inf\n"
     ]
    },
    {
     "ename": "ParallelSamplingError",
     "evalue": "Bad initial energy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/greg.bolla/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/parallel_sampling.py\", line 123, in _start_loop\n    point, stats = self._compute_point()\n  File \"/Users/greg.bolla/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/parallel_sampling.py\", line 154, in _compute_point\n    point, stats = self._step_method.step(self._point)\n  File \"/Users/greg.bolla/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/step_methods/arraystep.py\", line 247, in step\n    apoint, stats = self.astep(array)\n  File \"/Users/greg.bolla/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/step_methods/hmc/base_hmc.py\", line 149, in astep\n    raise SamplingError(\"Bad initial energy\")\npymc3.exceptions.SamplingError: Bad initial energy\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSamplingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;31mSamplingError\u001b[0m: Bad initial energy",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mParallelSamplingError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-72e95a24a00c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mturbidity_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, nuts_kwargs, step_kwargs, progressbar, model, random_seed, live_plot, discard_tuned_samples, live_plot_kwargs, compute_convergence_checks, use_mmap, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0m_print_step_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, use_mmap, **kwargs)\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m                         \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                         if (trace.supports_sampler_stats\n",
      "\u001b[0;32m~/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36mrecv_draw\u001b[0;34m(processes, timeout)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chain %s failed.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"writing_done\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/driven-data-rinse-over-run-w5STMFPe/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mParallelSamplingError\u001b[0m: Bad initial energy"
     ]
    }
   ],
   "source": [
    "with turbidity_model:\n",
    "    trace = pm.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
